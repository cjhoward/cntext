{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module cntext.stats in cntext:\n",
      "\n",
      "NAME\n",
      "    cntext.stats\n",
      "\n",
      "FUNCTIONS\n",
      "    cn_seg_sent(text)\n",
      "    \n",
      "    dict_pkl_list()\n",
      "        Get the list of cntext built-in dictionaries (pkl format)\n",
      "    \n",
      "    load_pkl_dict(file, is_builtin=True)\n",
      "        load pkl dictionary file,\n",
      "        :param file: pkl file path\n",
      "        :param is_builtin: Whether it is the built-in pkl file of cntext. Default True\n",
      "    \n",
      "    readability(text, zh_adjconj=None, language='chinese')\n",
      "        text readability, the larger the indicator, the higher the complexity of the article and the worse the readability.\n",
      "        :param text: text string\n",
      "        :param zh_adjconj Chinese conjunctions and adverbs, receive list data type. By default, the built-in dictionary of cntext is used\n",
      "        :param language: \"chinese\" or \"english\"; default is \"chinese\"\n",
      "        ------------\n",
      "        【English readability】english_readability = 4.71 x (characters/words) + 0.5 x (words/sentences) - 21.43；\n",
      "        【Chinese readability】  Refer 【徐巍,姚振晔,陈冬华.中文年报可读性：衡量与检验[J].会计研究,2021(03):28-44.】\n",
      "                     readability1  ---每个分句中的平均字数\n",
      "                     readability2  ---每个句子中副词和连词所占的比例\n",
      "                     readability3  ---参考Fog Index， readability3=(readability1+readability2)×0.5\n",
      "                     以上三个指标越大，都说明文本的复杂程度越高，可读性越差。\n",
      "    \n",
      "    sentiment(text, diction, language='chinese')\n",
      "        calculate the occurrences of each emotional category words in text;\n",
      "        the complex influence of intensity adverbs and negative words on emotion is not considered,\n",
      "        :param text:  text sring\n",
      "        :param diction:  emotion dictionary；\n",
      "        :param language: \"chinese\" or \"english\"; default language=\"chinese\"\n",
      "        \n",
      "        diction = {'category1':  'category1 emotion word list',\n",
      "                   'category2':  'category2 emotion word list',\n",
      "                   'category3':  'category3 emotion word list',\n",
      "                    ...\n",
      "                   }\n",
      "        :return:\n",
      "    \n",
      "    term_freq(text, language='chinese')\n",
      "        Calculate word count\n",
      "        :param text: text string\n",
      "        :param language: \"chinese\" or \"english\"; default is \"chinese\"\n",
      "\n",
      "DATA\n",
      "    ADV_words = ['都', '全', '单', '共', '光', '尽', '净', '仅', '就', '只', '一共', '...\n",
      "    CONJ_words = ['乃', '乍', '与', '无', '且', '丕', '为', '共', '其', '况', '厥', '...\n",
      "    STOPWORDS_en = ['upon', 'wouldn', \"isn't\", 'nothing', 'these', 'everyw...\n",
      "    STOPWORDS_zh = ['具体说来', '五', '无论', '＊', '与', '即若', '喂', '与其说', '不管', '...\n",
      "    __warningregistry__ = {'version': 213}\n",
      "\n",
      "FILE\n",
      "    /Library/Frameworks/anaconda3/lib/python3.9/site-packages/cntext/stats.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cntext as ct\n",
    "\n",
    "help(ct.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/sc/3mnt5tgs419_hk7s16gq61p80000gn/T/jieba.cache\n",
      "Loading model cost 0.596 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'致力于': 1, '文章': 1, '处理费': 1, '订阅费': 1, '发布': 1, '优质': 1, '研究': 1, '软件': 1})\n",
      "{'readability1': 23.0, 'readability2': 0.15384615384615385, 'readability3': 11.576923076923077}\n"
     ]
    }
   ],
   "source": [
    "import cntext as ct\n",
    "\n",
    "text = '致力于以零文章处理费或订阅费发布优质研究软件。'\n",
    "print(ct.term_freq(text, lang='chinese'))\n",
    "print(ct.readability(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'committed': 1, 'publishing': 1, 'quality': 1, 'research': 1, 'software': 1, 'zero': 1, 'article': 1, 'processing': 1, 'charges': 1, 'subscription': 1, 'fees.': 1})\n",
      "{'readability': 19.982}\n"
     ]
    }
   ],
   "source": [
    "import cntext as ct\n",
    "\n",
    "text = 'Committed to publishing quality research software with zero article processing charges or subscription fees.'\n",
    "print(ct.term_freq(text, lang='english'))\n",
    "print(ct.readability(text, lang='english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## built-in dictionary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DUTIR.pkl',\n",
       " 'HOWNET.pkl',\n",
       " 'sentiws.pkl',\n",
       " 'ChineseFinancialFormalUnformalSentiment.pkl',\n",
       " 'ANEW.pkl',\n",
       " 'LSD2015.pkl',\n",
       " 'NRC.pkl',\n",
       " 'geninqposneg.pkl',\n",
       " 'HuLiu.pkl',\n",
       " 'AFINN.pkl',\n",
       " 'ADV_CONJ.pkl',\n",
       " 'LoughranMcDonald.pkl',\n",
       " 'STOPWORDS.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cntext as ct\n",
    "\n",
    "ct.dict_pkl_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ct.load_pkl_dict('NRC.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sentiment in module cntext.stats:\n",
      "\n",
      "sentiment(text, diction, language='chinese')\n",
      "    calculate the occurrences of each emotional category words in text;\n",
      "    the complex influence of intensity adverbs and negative words on emotion is not considered,\n",
      "    :param text:  text sring\n",
      "    :param diction:  emotion dictionary；\n",
      "    :param language: 语言类型，\"chinese\"或\"english\"，默认\"chinese\"\n",
      "    \n",
      "    diction = {'category1':  'category1 emotion word list',\n",
      "               'category2':  'category2 emotion word list',\n",
      "               'category3':  'category3 emotion word list',\n",
      "                ...\n",
      "               }\n",
      "    :return:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ct.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'哀_num': 0,\n",
       " '好_num': 0,\n",
       " '惊_num': 0,\n",
       " '惧_num': 0,\n",
       " '乐_num': 2,\n",
       " '怒_num': 0,\n",
       " '恶_num': 0,\n",
       " 'stopword_num': 8,\n",
       " 'word_num': 14,\n",
       " 'sentence_num': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '我今天得奖了，很高兴，我要将快乐分享大家。'\n",
    "\n",
    "ct.sentiment(text=text,\n",
    "             diction=ct.load_pkl_dict('DUTIR.pkl')['DUTIR'],\n",
    "             lang='chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_num': 3,\n",
       " 'neg_num': 0,\n",
       " 'adv_num': 1,\n",
       " 'stopword_num': 8,\n",
       " 'word_num': 14,\n",
       " 'sentence_num': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction = {'pos': ['高兴', '快乐', '分享'],\n",
    "           'neg': ['难过', '悲伤'],\n",
    "           'adv': ['很', '特别']}\n",
    "\n",
    "text = '我今天得奖了，很高兴，我要将快乐分享大家。'\n",
    "ct.sentiment(text=text, \n",
    "             diction=diction, \n",
    "             lang='chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger_num': 0,\n",
       " 'anticipation_num': 1,\n",
       " 'disgust_num': 0,\n",
       " 'fear_num': 0,\n",
       " 'joy_num': 1,\n",
       " 'negative_num': 0,\n",
       " 'positive_num': 1,\n",
       " 'sadness_num': 0,\n",
       " 'surprise_num': 0,\n",
       " 'trust_num': 1,\n",
       " 'stopword_num': 1,\n",
       " 'word_num': 5,\n",
       " 'sentence_num': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'What a happy day!'\n",
    "\n",
    "ct.sentiment(text=text,\n",
    "             diction=ct.load_pkl_dict('NRC.pkl')['NRC'],\n",
    "             lang='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pos_num': 1,\n",
       " 'Neg_num': 0,\n",
       " 'Adv_num': 0,\n",
       " 'stopword_num': 1,\n",
       " 'word_num': 5,\n",
       " 'sentence_num': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cntext as ct\n",
    "\n",
    "text = 'What a happy day!'\n",
    "\n",
    "\n",
    "diction = {'Pos': ['happy', 'good'],\n",
    "           'Neg': ['bad', 'terrible'],\n",
    "           'Adv': ['very']}\n",
    "\n",
    "ct.sentiment(text=text,\n",
    "             diction=diction,\n",
    "             lang='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roadsweeper</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traindriver</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tush</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hairdress</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pharmaceutics</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  valence\n",
       "0    roadsweeper     4.85\n",
       "1    traindriver     4.54\n",
       "2           tush     4.45\n",
       "3      hairdress     3.93\n",
       "4  pharmaceutics     3.77"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cntext as ct\n",
    "\n",
    "# load the concreteness.pkl dictionary file\n",
    "concreteness_df = ct.load_pkl_dict('concreteness.pkl')\n",
    "concreteness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.856"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply = \"I'll go look for that\"\n",
    "\n",
    "score=ct.sentiment_by_valence(text=reply, \n",
    "                              diction=concreteness_df, \n",
    "                              lang='english')\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concreteness Score: 1.86 | Example-0: I'll go look for that\n",
      "Concreteness Score: 1.86 | Example-1: I'll go search for that\n",
      "Concreteness Score: 2.21 | Example-2: I'll go search for that top\n",
      "Concreteness Score: 2.04 | Example-3: I'll go search for that t-shirt\n",
      "Concreteness Score: 2.37 | Example-4: I'll go look for that t-shirt in grey\n",
      "Concreteness Score: 2.37 | Example-5: I'll go search for that t-shirt in grey\n"
     ]
    }
   ],
   "source": [
    "employee_replys = [\"I'll go look for that\",\n",
    "                   \"I'll go search for that\",\n",
    "                   \"I'll go search for that top\",\n",
    "                   \"I'll go search for that t-shirt\",\n",
    "                   \"I'll go look for that t-shirt in grey\",\n",
    "                   \"I'll go search for that t-shirt in grey\"]\n",
    "\n",
    "for idx, reply in enumerate(employee_replys):\n",
    "    score=ct.sentiment_by_valence(text=reply, \n",
    "                                  diction=concreteness_df, \n",
    "                                  lang='english')\n",
    "    \n",
    "    template = \"Concreteness Score: {score:.2f} | Example-{idx}: {exmaple}\"\n",
    "    \n",
    "    print(template.format(score=score, \n",
    "                          idx=idx, \n",
    "                          exmaple=reply))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
